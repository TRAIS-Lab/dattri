<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Hessian, HVP, and IHVP" href="hessian.html" /><link rel="prev" title="Tasks" href="task.html" />

    <!-- Generated with Sphinx 7.3.7 and Furo 2024.01.29 -->
        <title>Attributors - Dattri documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Dattri  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">Dattri  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Attribution Task and Attributors:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="task.html">Tasks</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Attributors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Low-level Utility Functions:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hessian.html">Hessian, HVP, and IHVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="fisher.html">Fisher Information Matrix (FIM) / IFVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="projection.html">Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="dropout.html">Dropout Ensemble</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark Functions</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="attributors">
<h1>Attributors<a class="headerlink" href="#attributors" title="Link to this heading">Â¶</a></h1>
<p id="module-dattri.algorithm.influence_function">This module implement the influence function.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ihvp_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'explicit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ihvp_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>Influence function attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ihvp_solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'explicit'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ihvp_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributor.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Influence function attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_func</strong> (<em>Callable</em>) â <p>The target function to be attributed.
The function can be quite flexible in terms of what is calculated,
but it should take the parameters and the dataloader as input.
A typical example is as follows:
<a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
&#64;flatten_func(model)
def f(params, dataloader):</p>
<blockquote>
<div><p>loss = nn.CrossEntropyLoss()
loss_val = 0
for image, label in dataloader:</p>
<blockquote>
<div><p>yhat = torch.func.functional_call(model, params, image)
loss_val += loss(yhat, label)</p>
</div></blockquote>
<p>return loss_val</p>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a>.
This examples calculates the loss of the model on the dataloader.</p>
</p></li>
<li><p><strong>params</strong> (<em>dict</em>) â <p>The parameters of the target function. The key is the
name of a parameter and the value is the parameter tensor.
TODO: This should be changed to support a list of parameters or</p>
<blockquote>
<div><p>paths for ensembling and memory efficiency.</p>
</div></blockquote>
</p></li>
<li><p><strong>ihvp_solver</strong> (<em>str</em>) â The solver for inverse hessian vector product
calculation, currently we only support âexplicitâ, âcgâ and âarnoldiâ.</p></li>
<li><p><strong>ihvp_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â Keyword arguments for ihvp solver.
calculation, currently we only support âexplicitâ, âcgâ, âarnoldiâ,
and âlissaâ.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â The device to run the attributor. Default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributor.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â The dataloader for
training samples to calculate the influence. It can be a subset
of the full training set if <cite>cache</cite> is called before. A subset
means that only a part of the training setâs influence is calculated.
The dataloader should not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â The dataloader for
test samples to calculate the influence. The dataloader should not                be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributor.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the dataset for inverse hessian calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) â The dataloader
with full training samples for inverse hessian calculation.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorArnoldi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precompute_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_constant</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with Arnoldi projection transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precompute_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_constant</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the Arnoldi projection attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>precompute_data_ratio</strong> (<em>float</em>) â Ratio of full training data used to
precompute the Arnoldi projector. Default is 1.0.</p></li>
<li><p><strong>proj_dim</strong> (<em>int</em>) â Dimension after projection. Corresponds to number of top
eigenvalues to keep for Hessian approximation.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) â Maximum iterations for Arnoldi Iteration. Default is 100.</p></li>
<li><p><strong>norm_constant</strong> (<em>float</em>) â Constant for the norm of the projected vector.
May need to be &gt; 1 for large number of parameters to avoid dividing the
projected vector by a very large normalization constant. Default is 1.0.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) â Convergence tolerance. Algorithm stops if the norm of the
current basis vector &lt; tol. Default is 1e-7.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) â Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) â Random seed for projector. Default is 0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the dataset and pre-calculate the Arnoldi projector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) â Dataloader with full training data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the test representations via Arnoldi projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
A 2-d tensor with shape (batch_size, num_params).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. A 2-d tensor with</dt><dd><p>shape (batch_size, proj_dim).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If the Arnoldi projector has not been cached.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations via Arnoldi projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â Train representations to be transformed.
A 2-d tensor with shape (batch_size, num_params).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed train representations. A 2-d tensor with</dt><dd><p>shape (batch_size, proj_dim).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If the Arnoldi projector has not been cached.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorCG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with CG inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the CG inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) â Maximum iterations for Conjugate Gradient Descent. Default
is 10.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) â Convergence tolerance. Algorithm stops if residual norm &lt; tol.
Default is 1e-7.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) â Auto-diff mode. Options:
- ârev-revâ: Two reverse-mode auto-diffs. Better compatibility, more
memory cost.
- ârev-fwdâ: Reverse-mode + forward-mode. Memory-efficient, less
compatible.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) â Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_cg.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorDataInf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fim_estimate_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with DataInf inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fim_estimate_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the DataInf inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) â Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
<li><p><strong>fim_estimate_data_ratio</strong> (<em>float</em>) â Ratio of full training data used to
approximate the empirical Fisher information matrix. Default is 1.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the dataset and pre-calculate the Arnoldi projector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) â Dataloader with full training data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the transformation on the test representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorEKFAC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with EK-FAC inverse FIM transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the EK-FAC inverse FIM attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â <p>The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>. The loss function for EK-FAC attributor should return
the following,
- loss: a single tensor of loss. Should be the mean loss by the</p>
<blockquote>
<div><p>batch size.</p>
</div></blockquote>
<ul>
<li><dl class="simple">
<dt>mask (optional): a tensor of shape (batch_size, t), where 1âs</dt><dd><p>indicate that the IFVP will be estimated on these
input positions and 0âs indicate that these positions
are irrelevant (e.g. padding tokens).</p>
</dd>
</dl>
</li>
</ul>
<p>t is the number of steps, or sequence length of the input data. If the
input data are non-sequential, t should be set to 1.
The FIM will be estimated on this function.</p>
</p></li>
<li><p><strong>module_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the module to be
used to calculate the train/test representations. If None, all linear
modules are used. This should be a string or a list of strings if
multiple modules are needed. The name of module should follow the
key of model.named_modules(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>damping</strong> (<em>float</em>) â Damping factor used for non-convexity in EK-FAC IFVP
calculation. Default is 0.0.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If there are multiple checkpoints in <cite>task</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the dataset and statistics for inverse FIM calculation.</p>
<p>Cache the full training dataset as other attributors.
Estimate and cache the covariance matrices, eigenvector matrices
and corrected eigenvalues based on the samples of training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) â The dataloader
with full training samples for inverse FIM calculation.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) â An integer indicating the maximum number of
batches that will be used for estimating the the covariance matrices
and lambdas. Default to length of <cite>full_train_dataloader</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the transformation on the test representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If specifies a non-zero <cite>ckpt_idx</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorExplicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with explicit inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the explicit inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â Task to attribute. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) â Regularization term added to Hessian matrix.
Useful for singular or ill-conditioned Hessian matrices.
Added as <cite>regularization * I</cite>, where <cite>I</cite> is the identity matrix.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_explicit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of model parameters. Used for ensembling.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorLiSSA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_repeat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recursion_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with LiSSA inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_repeat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recursion_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the LiSSA inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â Device to run the attributor on. Default is âcpuâ.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) â Batch size for LiSSA inner loop update. Default is 1.</p></li>
<li><p><strong>num_repeat</strong> (<em>int</em>) â Number of samples of the HVP approximation to average.
Default is 1.</p></li>
<li><p><strong>recursion_depth</strong> (<em>int</em>) â Number of recursions to estimate each IHVP sample.
Default is 5000.</p></li>
<li><p><strong>damping</strong> (<em>float</em>) â Damping factor for non-convexity in LiSSA IHVP calculation.</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) â Scaling factor for convergence in LiSSA IHVP calculation.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) â Auto-diff mode. Options:
- ârev-revâ: Two reverse-mode auto-diffs. Better compatibility, more
memory cost.
- ârev-fwdâ: Reverse-mode + forward-mode. Memory-efficient, less
compatible.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training setâs influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) â The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensorsâ shape follows (1, batch_size, â¦).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lissa_collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sampled_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn" title="Link to this definition">Â¶</a></dt>
<dd><p>Collate function for LISSA.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sampled_input</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) â The sampled input from the dataloader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The collated input for the LISSA.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Tensor, List[Tuple[Tensor, â¦]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_lissa.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) â Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep" title="Link to this definition">Â¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) â The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) â The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.tracin.</span></span><span class="sig-name descname"><span class="pre">TracInAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>TracIn attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the TracIn attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>weight_list</strong> (<em>Tensor</em>) â The weight used for the âweighted sumâ. For
TracIn/CosIn, this will contain a list of learning rates at each ckpt;
for Grad-Dot/Grad-Cos, this will be a list of ones.</p></li>
<li><p><strong>normalized_grad</strong> (<em>bool</em>) â Whether to apply normalization to gradients.</p></li>
<li><p><strong>projector_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) â The keyword arguments for the
projector.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â The device to run the attributor. Default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
training samples to calculate the influence. It can be a subset
of the full training set if <cite>cache</cite> is called before. A subset
means that only a part of the training setâs influence is calculated.
The dataloader should not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
test samples to calculate the influence. The dataloader should not
be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â The length of params_list and weight_list donât match.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Precompute and cache some values for efficiency.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.trak.</span></span><span class="sig-name descname"><span class="pre">TRAKAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_probability_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>TRAK attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_probability_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the TRAK attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>correct_probability_func</strong> (<em>Callable</em>) â <p>The function to calculate the
probability to correctly predict the label of the input data.
A typical example is as follows:
<a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>python
&#64;flatten_func(model)
def m(params, image_label_pair):</p>
<blockquote>
<div><p>image, label = image_label_pair
image_t = image.unsqueeze(0)
label_t = label.unsqueeze(0)
loss = nn.CrossEntropyLoss()
yhat = torch.func.functional_call(model, params, image_t)
p = torch.exp(-loss(yhat, label_t))
return p</p>
</div></blockquote>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a></p>
</p></li>
<li><p><strong>projector_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>) â The kwargs for the
random projection. Defaults to None.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) â The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â The device to run the attributor. Default is âcpuâ.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) â Regularization term add before matrix inversion.
Useful for singular or ill-conditioned matrices.
Added as <cite>regularization * I</cite>, where <cite>I</cite> is the identity matrix.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
training samples to calculate the influence. If <cite>cache</cite> is called before
<cite>attribute</cite>, this dataloader can consists of a subset of the full
training dataset cached in <cite>cache</cite>. In this case, only a part of the
training setâs influence will be calculated. The dataloader should not
be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
test samples to calculate the influence. The dataloader should not
be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If the train_dataloader is not None and the full training
    dataloader is cached or no train_loader is provided in both cases.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the dataset for gradient calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader
with full training samples for gradient calculation.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.rps.</span></span><span class="sig-name descname"><span class="pre">RPSAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_linear_layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_preactivate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>Representer point selection attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_linear_layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_preactivate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Representer point selection attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details. Notably, the target_func is required
to have inputs are list of pre-activation values (f_i in the paper) and
list of labels. Typical examples are loss functions such as BCELoss
and CELoss. We also assume the model has a final linear layer. RPS will
extract the final linear layerâs input and its parameter. The parameters
will be used for the initialization of the l2-finetuning. That is,
model_output = linear(second-to-last feature).</p></li>
<li><p><strong>final_linear_layer_name</strong> (<em>str</em>) â The name of the final linear layerâs name
in the model.</p></li>
<li><p><strong>normalize_preactivate</strong> (<em>bool</em>) â If set to true, then the intermediate layer
output will be normalized. The value of the output inner-product will
not be affected by the value of individual output magnitude.</p></li>
<li><p><strong>l2_strength</strong> (<em>float</em>) â The l2 regularization to fine-tune the last layer.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) â The number of epoch used to fine-tune the last layer.</p></li>
<li><p><strong>device</strong> (<em>str</em>) â The device to run the attributor. Default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) â The dataloader for training samples to
calculate the influence. It can be a subset of the full training set
if <cite>cache</cite> is called before. A subset means that only a part of the
training setâs influence is calculated. The dataloader should not be
shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) â The dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with the shape</dt><dd><p>of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Cache the full dataset for fine-tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) â The dataloader
with full training samples for the last linear layer
fine-tuning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.data_shapley.</span></span><span class="sig-name descname"><span class="pre">KNNShapleyAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor" title="Link to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>KNN Data Shapley Attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__" title="Link to this definition">Â¶</a></dt>
<dd><p>Initialize the AttributionTask.</p>
<p>KNN Data Shapley Valuation is generally dataset-specific.
Passing a model is optional and currently can be done in the
customizable distance function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k_neighbors</strong> (<em>int</em>) â The number of neighbors in KNN model.</p></li>
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) â The task to be attributed. Used to
pass the model and hook information in this attributor.
Please refer to the <cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>distance_func</strong> (<em>Callable</em><em>, </em><em>optional</em>) â <p>Customizable function
used for distance calculation in KNN. The function
can be quite flexible in terms of what is calculated,
but it should take two batches of data as input.
A typical example is as follows:
<a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>python
def f(batch_x, batch_y):</p>
<blockquote>
<div><p>coord1 = batch_x[0]
coord2 = batch_y[0]
return torch.cdist(coord1, coord2)</p>
</div></blockquote>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a>.
If not provided, a default Euclidean distance function
will be used.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>NotImplementedError</strong> â If task is not None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the KNN shapley values of the training set on each test sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
training samples to calculate the shapley values. The dataloader
should not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader for
test samples to calculate the shapley values. The dataloader
should not be shuffled.</p></li>
<li><p><strong>train_labels</strong> â (List[int], optional): The list of training labels,
with the same size and order of the training dataloader.
If not provided, the last element in each batch from the loader
will be used as label.</p></li>
<li><p><strong>test_labels</strong> â (List[int], optional): The list of test labels,
with the same size and order of the test dataloader.
If not provided, the last element in each batch from the loader
will be used as label.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The KNN shapley values of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> â If the length of provided labels and dataset mismatch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.cache" title="Link to this definition">Â¶</a></dt>
<dd><p>Precompute and cache some values for efficiency.</p>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="hessian.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Hessian, HVP, and IHVP</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="task.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tasks</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Dattri Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Attributors</a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributor"><code class="docutils literal notranslate"><span class="pre">IFAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributor.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.lissa_collate_fn()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor"><code class="docutils literal notranslate"><span class="pre">TracInAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.cache"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.cache"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor"><code class="docutils literal notranslate"><span class="pre">RPSAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.cache"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.cache"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.cache()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>