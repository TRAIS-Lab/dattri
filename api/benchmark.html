<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="prev" title="Dropout Ensemble" href="dropout.html" />

    <!-- Generated with Sphinx 7.3.7 and Furo 2024.01.29 -->
        <title>Benchmark Functions - Dattri documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Dattri  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">Dattri  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Attribution Methods:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="task.html">Tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="algorithm.html">Attributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="helper.html">Target Function Helpers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Low-level Utility Functions:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hvp_ihvp.html">HVP/IHVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="random_projection.html">Random Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="dropout.html">Dropout Ensemble</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark:</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Benchmark Functions</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="benchmark-functions">
<h1>Benchmark Functions<a class="headerlink" href="#benchmark-functions" title="Link to this heading">Â¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="dattri.model_utils.retrain.retrain_loo">
<span class="sig-prename descclassname"><span class="pre">dattri.model_utils.retrain.</span></span><span class="sig-name descname"><span class="pre">retrain_loo</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.model_utils.retrain.retrain_loo" title="Link to this definition">Â¶</a></dt>
<dd><p>Retrain the model for Leave-One-Out (LOO) metric.</p>
<p>The retrained model checkpoints and the removed index metadata are saved
to the <cite>path</cite>. The function will call the <cite>train_func</cite> to retrain the model
for each subset <cite>dataloader</cite> with one index removed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_func</strong> (<em>Callable</em>) â <p>The training function that takes a dataloader, and
returns the retrained model. Here is an example of a training function:
<a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
def train_func(dataloader):</p>
<blockquote>
<div><p>model = Model()
optimizer = â¦
criterion = â¦
model.train()
for inputs, labels in dataloader:</p>
<blockquote>
<div><p>optimizer.zero_grad()
outputs = model(inputs)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()</p>
</div></blockquote>
<p>return model</p>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
</p></li>
<li><p><strong>dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader used for training.</p></li>
<li><p><strong>indices</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) â The indices to remove from the dataloader. Default is None.
None means that each index in the dataloader will be removed in turn.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) â The random seed for the training process. Default is None,
which means the training process is not deterministic.</p></li>
<li><p><strong>**kwargs</strong> â The arguments of <cite>train_func</cite> in addition to dataloader.</p></li>
<li><p><strong>path</strong> (<em>str</em>) â <p>The directory to save the retrained models and the removed index
metadata. The directory should be organized as
<a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a></p>
<blockquote>
<div><dl>
<dt>/$path</dt><dd><p>metadata.yml
/index_{indices[0]}</p>
<blockquote>
<div><p>model_weights.pt</p>
</div></blockquote>
<dl class="simple">
<dt>/index_{indices[1]}</dt><dd><p>model_weights.pt</p>
</dd>
</dl>
<p>â¦
/index_{indices[n]}</p>
<blockquote>
<div><p>model_weights.pt</p>
</div></blockquote>
</dd>
</dl>
<p># metadata.yml
data = {</p>
<blockquote>
<div><p>âmodeâ: âlooâ,
âdata_lengthâ: len(dataloader),
âtrain_funcâ: train_func.__name__,
âindicesâ: indices,
âmap_index_dirâ: {</p>
<blockquote>
<div><p>indices[0]: fâ./index_{indices[0]}â,
indices[1]: fâ./index_{indices[1]}â,
â¦</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p>}</p>
</div></blockquote>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a>.</p>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.model_utils.retrain.retrain_lds">
<span class="sig-prename descclassname"><span class="pre">dattri.model_utils.retrain.</span></span><span class="sig-name descname"><span class="pre">retrain_lds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_subsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subset_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_runs_per_subset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_num_subsets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.model_utils.retrain.retrain_lds" title="Link to this definition">Â¶</a></dt>
<dd><p>Retrain the model for the Linear Datamodeling Score (LDS) metric calculation.</p>
<p>The retrained model checkpoints and the subset data indices metadata will be
saved to <cite>path</cite>. The function will call the <cite>train_func</cite> to retrain the model
for each subset <cite>dataloader</cite> with a random subset of the data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_func</strong> (<em>Callable</em>) â <p>The training function that takes a dataloader, and
returns the retrained model. Here is an example of a training function:
<a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>python
def train_func(dataloader, seed=None, <a href="#id21"><span class="problematic" id="id22">**</span></a>kargs):</p>
<blockquote>
<div><p>model = Model()
optimizer = â¦
criterion = â¦
model.train()
for inputs, labels in dataloader:</p>
<blockquote>
<div><p>optimizer.zero_grad()
outputs = model(inputs)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()</p>
</div></blockquote>
<p>return model</p>
</div></blockquote>
<p><a href="#id23"><span class="problematic" id="id24">``</span></a><a href="#id25"><span class="problematic" id="id26">`</span></a></p>
</p></li>
<li><p><strong>dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader used for training.</p></li>
<li><p><strong>path</strong> (<em>str</em>) â <p>The directory to save the retrained models and the subset
index metadata. The directory should be organized as
<a href="#id27"><span class="problematic" id="id28">``</span></a><a href="#id29"><span class="problematic" id="id30">`</span></a></p>
<blockquote>
<div><dl>
<dt>/$path</dt><dd><p>metadata.yml
/0</p>
<blockquote>
<div><p>model_weights_0.pt
model_weights_1.pt
â¦
model_weights_M.pt
indices.txt</p>
</div></blockquote>
<p>â¦
/N</p>
<blockquote>
<div><p>model_weights_0.pt
model_weights_1.pt
â¦
model_weights_M.pt
indices.txt</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p><a href="#id31"><span class="problematic" id="id32">``</span></a>`
where N is (num_subsets - 1) and M is (num_runs_per_subset - 1).</p>
</p></li>
<li><p><strong>num_subsets</strong> (<em>int</em>) â The number of subsets to retrain. Default is 100.</p></li>
<li><p><strong>subset_ratio</strong> (<em>float</em>) â The ratio of the subset to the whole dataset.
Default is 0.5.</p></li>
<li><p><strong>num_runs_per_subset</strong> (<em>int</em>) â The number of retraining runs for each subset.
Several runs can mitigate the randomness in training. Default is 1.</p></li>
<li><p><strong>start_id</strong> (<em>int</em>) â The starting index for the subset directory. Default is 0.
This is useful for parallelizing the retraining process.</p></li>
<li><p><strong>total_num_subsets</strong> (<em>int</em>) â The total number of subsets. Default is 0, which
means the total number of subsets is equal to <cite>num_subsets</cite>. This is
useful for parallelizing the retraining process.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) â The random seed for the training process and subset sampling.
Default is None, which means the training process and subset sampling
is not deterministic.</p></li>
<li><p><strong>**kargs</strong> â The arguments of <cite>train_func</cite> in addition to dataloader.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> â If <cite>total_num_subsets</cite> is negative.</p></li>
<li><p><strong>ValueError</strong> â If <cite>num_subsets</cite> does not divide <cite>total_num_subsets</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.metrics.ground_truth.calculate_loo_groundtruth">
<span class="sig-prename descclassname"><span class="pre">dattri.metrics.ground_truth.</span></span><span class="sig-name descname"><span class="pre">calculate_loo_groundtruth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrain_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.metrics.ground_truth.calculate_loo_groundtruth" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the groundtruth values for the Leave-One-Out (LOO) metric.</p>
<p>The LOO groundtruth is directly calculated by calculating the target value
difference for each sample in the test dataloader on each model in the
retrain directory. The target value is calculated by the target function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_func</strong> (<em>Callable</em>) â <p>The target function that takes a model and a dataloader
and returns the target value. An example of a target function like follows:
<a href="#id33"><span class="problematic" id="id34">``</span></a><a href="#id35"><span class="problematic" id="id36">`</span></a>python
def target_func(model, dataloader):</p>
<blockquote>
<div><p>model.eval()
with torch.no_grad():</p>
<blockquote>
<div><dl class="simple">
<dt>for inputs, labels in dataloader:</dt><dd><p>outputs = model(inputs)
# Do something with the outputs, e.g., calculate the loss.</p>
</dd>
</dl>
</div></blockquote>
<p>return target_value</p>
</div></blockquote>
<p><a href="#id37"><span class="problematic" id="id38">``</span></a><a href="#id39"><span class="problematic" id="id40">`</span></a></p>
</p></li>
<li><p><strong>retrain_dir</strong> (<em>str</em>) â The directory containing the retrained models. It should be
the directory saved by <cite>retrain_loo</cite>.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The dataloader where each of
the samples is used as the test set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple of two tensors. First is the LOO</dt><dd><p>groundtruth values for each sample in test_dataloader and each model in
retrain_dir. The returned tensor has the shape
(num_models, num_test_samples).
Second is the tensor indicating the removed index. The returned tensor has
the shape (num_models,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.metrics.ground_truth.calculate_lds_ground_truth">
<span class="sig-prename descclassname"><span class="pre">dattri.metrics.ground_truth.</span></span><span class="sig-name descname"><span class="pre">calculate_lds_ground_truth</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retrain_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.metrics.ground_truth.calculate_lds_ground_truth" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the ground-truth values for the Linear Datamodeling Score (LDS) metric.</p>
<p>Given a <cite>target_func</cite>, this function calculates the values of the <cite>target_func</cite> on
each sample in <cite>test_dataloader</cite>, and for each model in <cite>retrain_dir</cite>. These values
will be used as the ground-truth values for the LDS metric.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target_func</strong> (<em>Callable</em>) â <p>The target function that takes the path to a model
checkpoint and the <cite>test_dataloader</cite>, and returns the target values for all
test samples in this dataloader. Below is an example of a target function:
<a href="#id41"><span class="problematic" id="id42">``</span></a><a href="#id43"><span class="problematic" id="id44">`</span></a>python
def target_func(ckpt_path, dataloader):</p>
<blockquote>
<div><p>params = torch.load(ckpt_path)
model.load_state_dict(params)  # assuming model is defined somewhere
model.eval()
with torch.no_grad():</p>
<blockquote>
<div><dl class="simple">
<dt>for inputs, labels in dataloader:</dt><dd><p>outputs = model(inputs)
# Do something with the outputs, e.g., calculate the loss.</p>
</dd>
</dl>
</div></blockquote>
<p>return target_values</p>
</div></blockquote>
<p><a href="#id45"><span class="problematic" id="id46">``</span></a>`
This function should return a tensor of shape <cite>(num_test_samples,)</cite>
where each element is the target value for the corresponding sample.</p>
</p></li>
<li><p><strong>retrain_dir</strong> (<em>str</em>) â <p>The directory containing the retrained models. It should be
the directory saved by <cite>retrain_lds</cite>. The directory is organized as
<a href="#id47"><span class="problematic" id="id48">``</span></a><a href="#id49"><span class="problematic" id="id50">`</span></a></p>
<blockquote>
<div><dl>
<dt>/$path</dt><dd><p>metadata.yml
/0</p>
<blockquote>
<div><p>model_weights_0.pt
model_weights_1.pt
â¦
model_weights_M.pt
indices.txt</p>
</div></blockquote>
<p>â¦
/N</p>
<blockquote>
<div><p>model_weights_0.pt
model_weights_1.pt
â¦
model_weights_M.pt
indices.txt</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">additionally,</span> <span class="pre">the</span> <span class="pre">`metadata.yml`</span> <span class="pre">file</span> <span class="pre">includes</span> <span class="pre">the</span> <span class="pre">following</span> <span class="pre">information:</span>
<span class="pre">`</span></code></p>
<blockquote>
<div><dl>
<dt>{</dt><dd><p>ânum_subsetsâ: N,
ânum_runs_per_subsetâ: M,
âsubset_dir_mapâ: {</p>
<blockquote>
<div><p>0: â./0â,
â¦</p>
</div></blockquote>
</dd>
</dl>
<p>}</p>
</div></blockquote>
<p><a href="#id51"><span class="problematic" id="id52">``</span></a><a href="#id53"><span class="problematic" id="id54">`</span></a></p>
</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) â The test dataloader that will
be used to calculate the target values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple of two tensors. The first one has</dt><dd><p>the shape (num_subsets, num_test_samples), which contains the values of the
target function calculated on all test samples under <cite>num_subsets</cite> models,
each retrained on a subset of the training data. The second tensor has the
shape (num_subsets, subset_size), where each row refers to the indices of
the training samples used to retrain the model.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.benchmark.utils.flip_label">
<span class="sig-prename descclassname"><span class="pre">dattri.benchmark.utils.</span></span><span class="sig-name descname"><span class="pre">flip_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">np.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_space</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">np.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">np.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.benchmark.utils.flip_label" title="Link to this definition">Â¶</a></dt>
<dd><p>Flip the label of the input label tensor with the probability <cite>p</cite>.</p>
<p>The function will randomly select a new label from the <cite>label_space</cite> to replace
the original label.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>label</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>]</em>) â The label tensor to be flipped.</p></li>
<li><p><strong>label_space</strong> (<em>Union</em><em>[</em><em>list</em><em>, </em><em>np.ndarray</em><em>, </em><em>torch.Tensor</em><em>]</em>) â The label space to
sample the new label. If None, the label space will be inferred from the
unique values in the input label tensor.</p></li>
<li><p><strong>p</strong> (<em>float</em>) â The probability to flip the label.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple of two elements.</dt><dd><p>The first element is the flipped label tensor. The second element is
the flipped indices.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Union[np.ndarray, torch.Tensor], list]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.metrics.metrics.lds">
<span class="sig-prename descclassname"><span class="pre">dattri.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">lds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.metrics.metrics.lds" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the Linear Datamodeling Score (LDS) metric.</p>
<p>The LDS is calculated as the Spearman rank correlation between the predicted scores
and the ground truth values for each test sample across all retrained models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> (<em>torch.Tensor</em>) â The data attribution score tensor with the shape
(num_test_samples, num_train_samples).</p></li>
<li><p><strong>ground_truth</strong> (<em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em>) â A tuple of two tensors. The
first one has the shape (num_subsets, num_test_samples), which is the
ground-truth target values for all test samples under <cite>num_subsets</cite> models,
each retrained on a subset of the training data. The second tensor has the
shape (num_subsets, subset_size), where each row refers to the indices of
the training samples used to retrain the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>A tuple of two tensors. The first tensor</dt><dd><p>contains the Spearman rank correlation between the predicted scores and the
ground truth values for each test sample. The second tensor contains the
p-values of the correlation. Both have the shape (num_test_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.metrics.metrics.loo_corr">
<span class="sig-prename descclassname"><span class="pre">dattri.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">loo_corr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.metrics.metrics.loo_corr" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the Leave-One-Out (LOO) correlation metric.</p>
<p>The LOO correlation is calculated by pearson correlation between the score
tensor and the groundtruth.</p>
<p>TODO: more detailed description.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> (<em>torch.Tensor</em>) â The score tensor with the shape (num_train_samples,
num_test_samples).</p></li>
<li><p><strong>ground_truth</strong> (<em>torch.Tensor</em>) â A tuple of two tensors. First is the LOO
groundtruth values for each sample in test_dataloader and each model
in retrain_dir. The returned tensor has the shape (num_models,
num_test_samples). Second is the tensor indicating the removed index. The
returned tensor has the shape (num_models,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The LOO correlation metric value. The returned tensor has the</dt><dd><p>shape (num_test_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dattri.metrics.metrics.mislabel_detection_auc">
<span class="sig-prename descclassname"><span class="pre">dattri.metrics.metrics.</span></span><span class="sig-name descname"><span class="pre">mislabel_detection_auc</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ground_truth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.metrics.metrics.mislabel_detection_auc" title="Link to this definition">Â¶</a></dt>
<dd><p>Calculate the AUC using sorting algorithm.</p>
<p>The function will calculate the false positive rates and true positive rates
under different thresholds (number of data inspected), and return them with
the calculated auc (Area Under Curve).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> (<em>torch.Tensor</em>) â The self-attribution scores of shape (num_train_samples,).</p></li>
<li><p><strong>ground_truth</strong> (<em>torch.Tensor</em>) â A tensor indicating the noise index.
The returned binary tensor has the shape (num_train_samples,).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple with 2 items.
The first is the AUROC value (float),
the second is a Tuple with <cite>fpr, tpr, thresholds</cite> just like
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html</a>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(Tuple[float, Tuple[float, â¦]])</p>
</dd>
</dl>
</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="dropout.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Dropout Ensemble</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Dattri Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Benchmark Functions</a><ul>
<li><a class="reference internal" href="#dattri.model_utils.retrain.retrain_loo"><code class="docutils literal notranslate"><span class="pre">retrain_loo()</span></code></a></li>
<li><a class="reference internal" href="#dattri.model_utils.retrain.retrain_lds"><code class="docutils literal notranslate"><span class="pre">retrain_lds()</span></code></a></li>
<li><a class="reference internal" href="#dattri.metrics.ground_truth.calculate_loo_groundtruth"><code class="docutils literal notranslate"><span class="pre">calculate_loo_groundtruth()</span></code></a></li>
<li><a class="reference internal" href="#dattri.metrics.ground_truth.calculate_lds_ground_truth"><code class="docutils literal notranslate"><span class="pre">calculate_lds_ground_truth()</span></code></a></li>
<li><a class="reference internal" href="#dattri.benchmark.utils.flip_label"><code class="docutils literal notranslate"><span class="pre">flip_label()</span></code></a></li>
<li><a class="reference internal" href="#dattri.metrics.metrics.lds"><code class="docutils literal notranslate"><span class="pre">lds()</span></code></a></li>
<li><a class="reference internal" href="#dattri.metrics.metrics.loo_corr"><code class="docutils literal notranslate"><span class="pre">loo_corr()</span></code></a></li>
<li><a class="reference internal" href="#dattri.metrics.metrics.mislabel_detection_auc"><code class="docutils literal notranslate"><span class="pre">mislabel_detection_auc()</span></code></a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>