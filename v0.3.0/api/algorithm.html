<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html"><link rel="search" title="Search" href="../search.html"><link rel="next" title="Hessian, HVP, and IHVP" href="hessian.html"><link rel="prev" title="Tasks" href="task.html">

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.12.19 -->
        <title>Attributors - Dattri documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=7bdb33bb" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Dattri  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <span class="sidebar-brand-text">Dattri  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Attribution Task and Attributors:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="task.html">Tasks</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Attributors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Low-level Utility Functions:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hessian.html">Hessian, HVP, and IHVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="fisher.html">Fisher Information Matrix (FIM) / IFVP</a></li>
<li class="toctree-l1"><a class="reference internal" href="projection.html">Projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="dropout.html">Dropout Ensemble</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmark:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">Benchmark Functions</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/api/algorithm.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="attributors">
<h1>Attributors<a class="headerlink" href="#attributors" title="Link to this heading">¶</a></h1>
<p id="module-dattri.algorithm.influence_function">This module implement the influence function.</p>
<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorArnoldi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precompute_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_constant</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with Arnoldi projection transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precompute_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_constant</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the Arnoldi projection attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>precompute_data_ratio</strong> (<em>float</em>) – Ratio of full training data used to
precompute the Arnoldi projector. Default is 1.0.</p></li>
<li><p><strong>proj_dim</strong> (<em>int</em>) – Dimension after projection. Corresponds to number of top
eigenvalues to keep for Hessian approximation.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) – Maximum iterations for Arnoldi Iteration. Default is 100.</p></li>
<li><p><strong>norm_constant</strong> (<em>float</em>) – Constant for the norm of the projected vector.
May need to be &gt; 1 for large number of parameters to avoid dividing the
projected vector by a very large normalization constant. Default is 1.0.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) – Convergence tolerance. Algorithm stops if the norm of the
current basis vector &lt; tol. Default is 1e-7.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) – Random seed for projector. Default is 0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the dataset and pre-calculate the Arnoldi projector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) – Dataloader with full training data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the test representations via Arnoldi projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
A 2-d tensor with shape (batch_size, num_params).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. A 2-d tensor with</dt><dd><p>shape (batch_size, proj_dim).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the Arnoldi projector has not been cached.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations via Arnoldi projection.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – Train representations to be transformed.
A 2-d tensor with shape (batch_size, num_params).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed train representations. A 2-d tensor with</dt><dd><p>shape (batch_size, proj_dim).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the Arnoldi projector has not been cached.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorCG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with CG inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1e-07</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the CG inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em>) – Maximum iterations for Conjugate Gradient Descent. Default
is 10.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) – Convergence tolerance. Algorithm stops if residual norm &lt; tol.
Default is 1e-7.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Auto-diff mode. Options:
- “rev-rev”: Two reverse-mode auto-diffs. Better compatibility, more
memory cost.
- “rev-fwd”: Reverse-mode + forward-mode. Memory-efficient, less
compatible.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_cg.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorDataInf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fim_estimate_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with DataInf inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fim_estimate_data_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the DataInf inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – Regularization term for Hessian vector product.
Adding <cite>regularization * I</cite> to the Hessian matrix, where <cite>I</cite> is the
identity matrix. Useful for singular or ill-conditioned matrices.
Default is 0.0.</p></li>
<li><p><strong>fim_estimate_data_ratio</strong> (<em>float</em>) – Ratio of full training data used to
approximate the empirical Fisher information matrix. Default is 1.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the dataset and pre-calculate the Arnoldi projector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) – Dataloader with full training data.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the transformation on the test representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorEKFAC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with EK-FAC inverse FIM transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">module_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the EK-FAC inverse FIM attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – <p>The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>. The loss function for EK-FAC attributor should return
the following,
- loss: a single tensor of loss. Should be the mean loss by the</p>
<blockquote>
<div><p>batch size.</p>
</div></blockquote>
<ul>
<li><dl class="simple">
<dt>mask (optional): a tensor of shape (batch_size, t), where 1’s</dt><dd><p>indicate that the IFVP will be estimated on these
input positions and 0’s indicate that these positions
are irrelevant (e.g. padding tokens).</p>
</dd>
</dl>
</li>
</ul>
<p>t is the number of steps, or sequence length of the input data. If the
input data are non-sequential, t should be set to 1.
The FIM will be estimated on this function.</p>
</p></li>
<li><p><strong>module_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the module to be
used to calculate the train/test representations. If None, all linear
modules are used. This should be a string or a list of strings if
multiple modules are needed. The name of module should follow the
key of model.named_modules(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>damping</strong> (<em>float</em>) – Damping factor used for non-convexity in EK-FAC IFVP
calculation. Default is 0.0.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If there are multiple checkpoints in <cite>task</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the dataset and statistics for inverse FIM calculation.</p>
<p>Cache the full training dataset as other attributors.
Estimate and cache the covariance matrices, eigenvector matrices
and corrected eigenvalues based on the samples of training data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) – The dataloader
with full training samples for inverse FIM calculation.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>optional</em>) – An integer indicating the maximum number of
batches that will be used for estimating the the covariance matrices
and lambdas. Default to length of <cite>full_train_dataloader</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the transformation on the test representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If specifies a non-zero <cite>ckpt_idx</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorExplicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with explicit inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the explicit inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – Task to attribute. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – Regularization term added to Hessian matrix.
Useful for singular or ill-conditioned Hessian matrices.
Added as <cite>regularization * I</cite>, where <cite>I</cite> is the identity matrix.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_explicit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of model parameters. Used for ensembling.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.influence_function.</span></span><span class="sig-name descname"><span class="pre">IFAttributorLiSSA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_repeat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recursion_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseInnerProductAttributor</span></code></p>
<p>The inner product attributor with LiSSA inverse hessian transformation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_repeat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recursion_depth</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'rev-rev'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the LiSSA inverse Hessian attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Must be an instance of
<cite>AttributionTask</cite>.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – Device to run the attributor on. Default is “cpu”.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Batch size for LiSSA inner loop update. Default is 1.</p></li>
<li><p><strong>num_repeat</strong> (<em>int</em>) – Number of samples of the HVP approximation to average.
Default is 1.</p></li>
<li><p><strong>recursion_depth</strong> (<em>int</em>) – Number of recursions to estimate each IHVP sample.
Default is 5000.</p></li>
<li><p><strong>damping</strong> (<em>float</em>) – Damping factor for non-convexity in LiSSA IHVP calculation.</p></li>
<li><p><strong>scaling</strong> (<em>float</em>) – Scaling factor for convergence in LiSSA IHVP calculation.</p></li>
<li><p><strong>mode</strong> (<em>str</em>) – Auto-diff mode. Options:
- “rev-rev”: Two reverse-mode auto-diffs. Better compatibility, more
memory cost.
- “rev-fwd”: Reverse-mode + forward-mode. Memory-efficient, less
compatible.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – Dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the full training dataloader or precompute and cache more information.</p>
<p>By default, the cache function only caches the full training dataloader.
Subclasses may override this function to precompute and cache more information.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – Dataloader for
the full training data. Ideally, the batch size of the dataloader
should be the same as the number of training samples to get the
best accuracy for some attributors. Smaller batch size may lead to
a less accurate result but lower memory consumption.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep">
<span class="sig-name descname"><span class="pre">generate_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of test data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial test representations.</p>
<p>The default implementation calculates the gradient of the test loss with respect
to the parameter. Subclasses may override this function to calculate something
else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The test data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the test data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep">
<span class="sig-name descname"><span class="pre">generate_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Generate initial representations of train data.</p>
<p>Inner product attributors calculate the inner product between the (transformed)
train representations and test representations. This function generates the
initial train representations.</p>
<p>The default implementation calculates the gradient of the train loss with
respect to the parameter. Subclasses may override this function to
calculate something else.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>data</strong> (<em>Tuple</em><em>[</em><em>Tensor</em><em>]</em>) – The train data. Typically, this is a tuple
of input data and target data but the number of items in this
tuple should align with the corresponding argument in the
target function. The tensors’ shape follows (1, batch_size, …).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The initial representations of the train data. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">lissa_collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sampled_input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn" title="Link to this definition">¶</a></dt>
<dd><p>Collate function for LISSA.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sampled_input</strong> (<em>List</em><em>[</em><em>Tensor</em><em>]</em>) – The sampled input from the dataloader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The collated input for the LISSA.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[Tensor, List[Tuple[Tensor, …]]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relatif_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – Dataloader for training samples to
calculate the influence. It can be a subset of the full training
set if <cite>cache</cite> is called before. A subset means that only a part
of the training set’s influence is calculated. The dataloader should
not be shuffled.</p></li>
<li><p><strong>relatif_method</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – Method for normalizing the
influence values.
Supported options:
- <cite>“l”</cite>: Normalizes by <cite>sqrt(g_i^T (H^-1 g_i))</cite>.
- <cite>“theta”</cite>: Normalizes by <cite>||H^-1 g_i||</cite>.
- <cite>None</cite>: No normalization applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep">
<span class="sig-name descname"><span class="pre">transform_test_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the transformation on the test rep through ihvp_lissa.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – Index of the model checkpoints. Used for ensembling
different trained model checkpoints.</p></li>
<li><p><strong>test_rep</strong> (<em>torch.Tensor</em>) – Test representations to be transformed.
Typically a 2-d tensor with shape (batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Transformed test representations. Typically a 2-d</dt><dd><p>tensor with shape (batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep">
<span class="sig-name descname"><span class="pre">transform_train_rep</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_rep</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep" title="Link to this definition">¶</a></dt>
<dd><p>Transform the train representations.</p>
<p>Inner product attributor calculates the inner product between the (transformed)
train representations and test representations. This function calculates the
transformation of the train representations. For example, the transformation
could be a dimension reduction of the train representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ckpt_idx</strong> (<em>int</em>) – The index of the model checkpoints. This index
is used for ensembling different trained model checkpoints.</p></li>
<li><p><strong>train_rep</strong> (<em>torch.Tensor</em>) – The train representations to be transformed.
Typically, it is a 2-d dimensional tensor with the shape of
(batch_size, num_parameters).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The transformed train representations. Typically,</dt><dd><p>it is a 2-d dimensional tensor with the shape of
(batch_size, transformed_dimension).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.tracin.</span></span><span class="sig-name descname"><span class="pre">TracInAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>TracIn attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the TracIn attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>weight_list</strong> (<em>Tensor</em>) – The weight used for the “weighted sum”. For
TracIn/CosIn, this will contain a list of learning rates at each ckpt;
for Grad-Dot/Grad-Cos, this will be a list of ones.</p></li>
<li><p><strong>normalized_grad</strong> (<em>bool</em>) – Whether to apply normalization to gradients.</p></li>
<li><p><strong>projector_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – The keyword arguments for the
projector.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The device to run the attributor. Default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
training samples to calculate the influence. It can be a subset
of the full training set if <cite>cache</cite> is called before. A subset
means that only a part of the training set’s influence is calculated.
The dataloader should not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
test samples to calculate the influence. The dataloader should not
be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – The length of params_list and weight_list don’t match.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Precompute and cache some values for efficiency.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.tracin.TracInAttributor.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.tracin.TracInAttributor.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
training samples to calculate the influence. It can be a subset
of the full training set if <cite>cache</cite> is called before. A subset
means that only a part of the training set’s influence is calculated.
The dataloader should not be shuffled.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – The length of params_list and weight_list don’t match.</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.trak.</span></span><span class="sig-name descname"><span class="pre">TRAKAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_probability_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>TRAK attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_probability_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regularization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the TRAK attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>correct_probability_func</strong> (<em>Callable</em>) – <p>The function to calculate the
probability to correctly predict the label of the input data.
A typical example is as follows:
<a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
&#64;flatten_func(model)
def m(params, image_label_pair):</p>
<blockquote>
<div><p>image, label = image_label_pair
image_t = image.unsqueeze(0)
label_t = label.unsqueeze(0)
loss = nn.CrossEntropyLoss()
yhat = torch.func.functional_call(model, params, image_t)
p = torch.exp(-loss(yhat, label_t))
return p</p>
</div></blockquote>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
</p></li>
<li><p><strong>projector_kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>optional</em>) – The kwargs for the
random projection. Defaults to None.</p></li>
<li><p><strong>layer_name</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>str</em><em>]</em><em>]</em><em>]</em>) – The name of the layer to be
used to calculate the train/test representations. If None, full
parameters are used. This should be a string or a list of strings
if multiple layers are needed. The name of layer should follow the
key of model.named_parameters(). Default: None.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The device to run the attributor. Default is “cpu”.</p></li>
<li><p><strong>regularization</strong> (<em>float</em>) – Regularization term add before matrix inversion.
Useful for singular or ill-conditioned matrices.
Added as <cite>regularization * I</cite>, where <cite>I</cite> is the identity matrix.
Default is 0.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
training samples to calculate the influence. If <cite>cache</cite> is called before
<cite>attribute</cite>, this dataloader can consists of a subset of the full
training dataset cached in <cite>cache</cite>. In this case, only a part of the
training set’s influence will be calculated. The dataloader should not
be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
test samples to calculate the influence. The dataloader should not
be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the train_dataloader is not None and the full training
    dataloader is cached or no train_loader is provided in both cases.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the dataset for gradient calculation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader
with full training samples for gradient calculation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.trak.TRAKAttributor.self_attribute">
<span class="sig-name descname"><span class="pre">self_attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.trak.TRAKAttributor.self_attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
training samples to calculate the influence. If <cite>cache</cite> is called before
<cite>attribute</cite>, this dataloader can consists of a subset of the full
training dataset cached in <cite>cache</cite>. In this case, only a part of the
training set’s influence will be calculated. The dataloader should not
be shuffled.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on itself, with</dt><dd><p>the shape of (num_train_samples,).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the train_dataloader is not None and the full training
    dataloader is cached or no train_loader is provided in both cases.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.rps.</span></span><span class="sig-name descname"><span class="pre">RPSAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_linear_layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_preactivate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>Representer point selection attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_linear_layer_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_preactivate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2_strength</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Representer point selection attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Please refer to the
<cite>AttributionTask</cite> for more details. Notably, the target_func is required
to have inputs are list of pre-activation values (f_i in the paper) and
list of labels. Typical examples are loss functions such as BCELoss
and CELoss. We also assume the model has a final linear layer. RPS will
extract the final linear layer’s input and its parameter. The parameters
will be used for the initialization of the l2-finetuning. That is,
model_output = linear(second-to-last feature).</p></li>
<li><p><strong>final_linear_layer_name</strong> (<em>str</em>) – The name of the final linear layer’s name
in the model.</p></li>
<li><p><strong>normalize_preactivate</strong> (<em>bool</em>) – If set to true, then the intermediate layer
output will be normalized. The value of the output inner-product will
not be affected by the value of individual output magnitude.</p></li>
<li><p><strong>l2_strength</strong> (<em>float</em>) – The l2 regularization to fine-tune the last layer.</p></li>
<li><p><strong>epoch</strong> (<em>int</em>) – The number of epoch used to fine-tune the last layer.</p></li>
<li><p><strong>device</strong> (<em>str</em>) – The device to run the attributor. Default is cpu.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the influence of the training set on the test set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>DataLoader</em>) – The dataloader for training samples to
calculate the influence. It can be a subset of the full training set
if <cite>cache</cite> is called before. A subset means that only a part of the
training set’s influence is calculated. The dataloader should not be
shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>DataLoader</em>) – The dataloader for test samples to calculate
the influence. The dataloader should not be shuffled.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The influence of the training set on the test set, with the shape</dt><dd><p>of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.rps.RPSAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.rps.RPSAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache the full dataset for fine-tuning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> (<em>DataLoader</em>) – The dataloader
with full training samples for the last linear layer
fine-tuning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.data_shapley.</span></span><span class="sig-name descname"><span class="pre">KNNShapleyAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>KNN Data Shapley Attributor.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">k_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize the AttributionTask.</p>
<p>KNN Data Shapley Valuation is generally dataset-specific.
Passing a model is optional and currently can be done in the
customizable distance function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>k_neighbors</strong> (<em>int</em>) – The number of neighbors in KNN model.</p></li>
<li><p><strong>task</strong> (<a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><em>AttributionTask</em></a>) – The task to be attributed. Used to
pass the model and hook information in this attributor.
Please refer to the <cite>AttributionTask</cite> for more details.</p></li>
<li><p><strong>distance_func</strong> (<em>Callable</em><em>, </em><em>optional</em>) – <p>Customizable function
used for distance calculation in KNN. The function
can be quite flexible in terms of what is calculated,
but it should take two batches of data as input.
A typical example is as follows:
<a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>python
def f(batch_x, batch_y):</p>
<blockquote>
<div><p>coord1 = batch_x[0]
coord2 = batch_y[0]
return torch.cdist(coord1, coord2)</p>
</div></blockquote>
<p><a href="#id13"><span class="problematic" id="id14">``</span></a><a href="#id15"><span class="problematic" id="id16">`</span></a>.
If not provided, a default Euclidean distance function
will be used.</p>
</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>NotImplementedError</strong> – If task is not None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.utils.data.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculate the KNN shapley values of the training set on each test sample.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
training samples to calculate the shapley values. The dataloader
should not be shuffled.</p></li>
<li><p><strong>test_dataloader</strong> (<em>torch.utils.data.DataLoader</em>) – The dataloader for
test samples to calculate the shapley values. The dataloader
should not be shuffled.</p></li>
<li><p><strong>train_labels</strong> – (List[int], optional): The list of training labels,
with the same size and order of the training dataloader.
If not provided, the last element in each batch from the loader
will be used as label.</p></li>
<li><p><strong>test_labels</strong> – (List[int], optional): The list of test labels,
with the same size and order of the test dataloader.
If not provided, the last element in each batch from the loader
will be used as label.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>The KNN shapley values of the training set on the test set, with</dt><dd><p>the shape of (num_train_samples, num_test_samples).</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the length of provided labels and dataset mismatch.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.data_shapley.KNNShapleyAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Precompute and cache some values for efficiency.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.LoGraAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.</span></span><span class="sig-name descname"><span class="pre">LoGraAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.LoGraAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor" title="dattri.algorithm.block_projected_if.block_projected_if.BlockProjectedIFAttributor"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor</span></code></a></p>
<p>LoGra Attributor.</p>
<p>Low-Rank Gradient Projection (LoGra) attributor that uses normal projection
for the first stage and identity projection (no compression) for the second
stage.</p>
<p>This is equivalent to the original LoGra method from the paper.</p>
<p>The projection is factorized: if you specify proj_dim=4096, each component
will have dimension sqrt(4096)=64, and the Kronecker product will have
dimension 4096.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.LoGraAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.LoGraAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize LoGra attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> – Attribution task containing model, loss function, and checkpoints</p></li>
<li><p><strong>layer_names</strong> – Names of layers where gradients will be collected.
If None, uses all Linear layers.</p></li>
<li><p><strong>hessian</strong> – Type of Hessian approximation (“Identity”, “eFIM”).</p></li>
<li><p><strong>damping</strong> – Damping factor for Hessian inverse (when hessian=”eFIM”)</p></li>
<li><p><strong>device</strong> – Device to run computations on</p></li>
<li><p><strong>proj_dim</strong> – Projection dimension after Kronecker product (default:
4096). Must be a perfect square. The per-component dimension
will be √proj_dim. For example, proj_dim=4096 gives
per-component dim of 64.</p></li>
<li><p><strong>offload</strong> – Memory management strategy (“none”, “cpu”, “disk”)</p></li>
<li><p><strong>cache_dir</strong> – Directory for caching (required when offload=”disk”)</p></li>
<li><p><strong>chunk_size</strong> – Chunk size for processing in disk offload</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If proj_dim is not a perfect square.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.block_projected_if.</span></span><span class="sig-name descname"><span class="pre">BlockProjectedIFAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsifier_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseAttributor</span></code></p>
<p>Block-Projected Influence Function Attributor.</p>
<p>A general attributor that computes influence scores using a two-stage
compression pipeline with projected gradients for efficiency.
Uses hooks to capture per-sample gradients and applies random projections.</p>
<p>This is a general implementation that supports arbitrary compressor configurations.
For specific methods like LoGra or FactGraSS, use the wrapper classes.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparsifier_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projector_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize Block-Projected IF attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> – Attribution task containing model, loss function, and checkpoints</p></li>
<li><p><strong>layer_names</strong> – Names of layers where gradients will be collected.
If None, uses all Linear layers.
You can check the names using model.named_modules().
HookManager will register hooks to named layers.</p></li>
<li><p><strong>hessian</strong> – Type of Hessian approximation (“Identity”, “eFIM”). For
“Identity”, the hessian will be taken as the identity matrix.
For “eFIM”, the hessian will be computed as the empirical
fisher information matrix.</p></li>
<li><p><strong>damping</strong> – Damping factor for Hessian inverse (when hessian=”eFIM”)</p></li>
<li><p><strong>device</strong> – Device to run computations on</p></li>
<li><p><strong>sparsifier_kwargs</strong> – Arguments for sparsifier stage (first stage compression)</p></li>
<li><p><strong>projector_kwargs</strong> – Arguments for projector stage (second stage compression).
If None, defaults to identity projection (no further compression).</p></li>
<li><p><strong>offload</strong> – Memory management strategy (“none”, “cpu”, “disk”), stating
the place to offload the gradients.
“cpu”: stores gradients on CPU and moves to device when needed.
“disk”: stores gradients on disk and moves to device when needed.</p></li>
<li><p><strong>cache_dir</strong> – Directory for caching (required when offload=”disk”).</p></li>
<li><p><strong>chunk_size</strong> – Chunk size for processing in disk offload.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If cache_dir is None when offload=”disk”.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Compute influence scores between training and test samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataloader</strong> – Training data (can be subset if cache was called)</p></li>
<li><p><strong>test_dataloader</strong> – Test data to compute influence for</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Influence score tensor of shape (num_train, num_test)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">full_train_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Cache gradients and IFVP for the full training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>full_train_dataloader</strong> – DataLoader for full training data</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_ifvp">
<span class="sig-name descname"><span class="pre">compute_ifvp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_ifvp" title="Link to this definition">¶</a></dt>
<dd><p>Compute inverse-Hessian-vector products (IFVP).</p>
<p>Here we use empirical fisher information matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ValueError</strong> – If layer dimensions are not found.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_preconditioners">
<span class="sig-name descname"><span class="pre">compute_preconditioners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_preconditioners" title="Link to this definition">¶</a></dt>
<dd><p>Compute preconditioners (inverse Hessian) from gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>damping</strong> – Damping factor for numerical stability</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If layer dimensions are not found.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_self_attribution">
<span class="sig-name descname"><span class="pre">compute_self_attribution</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_self_attribution" title="Link to this definition">¶</a></dt>
<dd><p>Compute self-influence scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Self-influence scores</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.factgrass.FactGraSSAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.factgrass.</span></span><span class="sig-name descname"><span class="pre">FactGraSSAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blowup_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.factgrass.FactGraSSAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor" title="dattri.algorithm.block_projected_if.block_projected_if.BlockProjectedIFAttributor"><code class="xref py py-class docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor</span></code></a></p>
<p>FactGraSS Attributor.</p>
<p>Factorized Gradient Sketching with Structured Sparsity (FactGraSS)
attributor that uses random mask projection for the first stage and SJLT
(Sparse Johnson-Lindenstrauss Transform) for the second stage.</p>
<p>This is a follow-up work to LoGra that provides better compression by
using a two-stage compression pipeline.</p>
<p>The first stage is factorized with a blowup factor:
- If proj_dim=4096 and blowup_factor=4:</p>
<blockquote>
<div><ul class="simple">
<li><p>Intermediate dimension = 4096 * 4 = 16384</p></li>
<li><p>Per-component dimension = sqrt(16384) = 128</p></li>
<li><p>After second stage: final dimension = 4096</p></li>
</ul>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.factgrass.FactGraSSAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hessian</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'Identity'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'eFIM'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'eFIM'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">damping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4096</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">blowup_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offload</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'none'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'cpu'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'disk'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.factgrass.FactGraSSAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialize FactGraSS attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> – Attribution task containing model, loss function, and checkpoints</p></li>
<li><p><strong>layer_names</strong> – Names of layers where gradients will be collected.
If None, uses all Linear layers.</p></li>
<li><p><strong>hessian</strong> – Type of Hessian approximation (“Identity”, “eFIM”).</p></li>
<li><p><strong>damping</strong> – Damping factor for Hessian inverse (when hessian=”eFIM”)</p></li>
<li><p><strong>device</strong> – Device to run computations on</p></li>
<li><p><strong>proj_dim</strong> – Projection dimension after second stage (default: 4096).</p></li>
<li><p><strong>blowup_factor</strong> – Multiplier for intermediate dimension after
sparsification (default: 4). The intermediate dimension will be
proj_dim * blowup_factor, which must be a perfect square for
factorized projection. For example, proj_dim=4096 and
blowup_factor=4 gives intermediate_dim=16384, per-component
dim=128.</p></li>
<li><p><strong>offload</strong> – Memory management strategy (“none”, “cpu”, “disk”)</p></li>
<li><p><strong>cache_dir</strong> – Directory for caching (required when offload=”disk”)</p></li>
<li><p><strong>chunk_size</strong> – Chunk size for processing in disk offload</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If intermediate_dim (proj_dim * blowup_factor) is not
    a perfect square.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dattri.algorithm.dvemb.</span></span><span class="sig-name descname"><span class="pre">DVEmbAttributor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factorization_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Data Value Embedding (DVEmb) attributor.</p>
<p>DVEmb captures temporal dependence in training by computing data value embeddings
that approximate trajectory-specific leave-one-out influence. This implementation
stores embeddings for each epoch separately, allowing for epoch-specific analysis.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="task.html#dattri.task.AttributionTask" title="dattri.task.AttributionTask"><span class="pre">AttributionTask</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factorization_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initializes the DVEmb attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>task</strong> – <p>Task to attribute. Must be an instance of <cite>AttributionTask</cite>.
Note: The checkpoint functionality of the task is not used by DVEmb.
The loss function of the task must follow specific formats:</p>
<blockquote>
<div><ul>
<li><p>If <cite>factorization_type</cite> is “none”, the loss function should follow
the signature of the following example:</p>
<blockquote>
<div><p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>python
def f(params, data):</p>
<blockquote>
<div><p>image, label = data
loss = nn.CrossEntropyLoss()
yhat = torch.func.functional_call(model, params, image)
return loss(yhat, label)</p>
</div></blockquote>
<p><a href="#id21"><span class="problematic" id="id22">``</span></a><a href="#id23"><span class="problematic" id="id24">`</span></a>.</p>
</div></blockquote>
</li>
<li><p>If <cite>factorization_type</cite> is not “none”, the loss function should
follow the signature of the following example:</p>
<blockquote>
<div><p><a href="#id25"><span class="problematic" id="id26">``</span></a><a href="#id27"><span class="problematic" id="id28">`</span></a>python
def f(model, data, device):</p>
<blockquote>
<div><p>image, label = data
loss = nn.CrossEntropyLoss()
yhat = model(image.to(device))
return loss(yhat, label.to(device))</p>
</div></blockquote>
<p><a href="#id29"><span class="problematic" id="id30">``</span></a><a href="#id31"><span class="problematic" id="id32">`</span></a>.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>proj_dim</strong> – The dimension for projection (if used). Defaults to None,
meaning no projection.</p></li>
<li><p><strong>proj_seed</strong> – Random seed for projection. Defaults to 0.</p></li>
<li><p><strong>factorization_type</strong> – Type of gradient factorization to use. Options are
“none” (default),
“kronecker” (same as in the paper),
or “elementwise” (efficiently projects Kronecker
products via factorized elementwise products).</p></li>
<li><p><strong>layer_names</strong> – Names of layers where gradients will be collected.
If None, uses all Linear layers.
You can check the names using model.named_modules().
Hooks will be registered on these layers to collect gradients.
Will only be used when factorization_type is not “none”.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If an unknown factorization type is provided
    or if no Linear layers are found for factorization or
    if the loss function format is incorrect.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor.attribute" title="Link to this definition">¶</a></dt>
<dd><p>Calculates influence scores for a test set for one or all epochs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>test_dataloader</strong> – A dataloader for the test set.</p></li>
<li><p><strong>epoch</strong> – Optional. If specified, returns scores using embeddings from that
epoch. If None, returns scores based on the sum of embeddings
across all epochs.</p></li>
<li><p><strong>train_data_indices</strong> – Optional. A list of training sample indices for which
to compute influence. If None, computes for all.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of influence scores.</p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>RuntimeError</strong> – If embeddings have not been computed by calling
    <cite>cache</cite> first, or if a projection dimension
    was specified but the projector is not initialized.</p></li>
<li><p><strong>ValueError</strong> – If embeddings for the specified <cite>epoch</cite> are not found.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor.cache">
<span class="sig-name descname"><span class="pre">cache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradients</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_saving</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor.cache" title="Link to this definition">¶</a></dt>
<dd><p>Computes data value embeddings for each epoch separately.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradients</strong> – Optional external gradients instead of cached ones
(e.g., (epoch -&gt; list of per-sample gradients)).</p></li>
<li><p><strong>learning_rates</strong> – Optional external learning rates instead of cached ones
(e.g., (epoch -&gt; list of learning rates)).</p></li>
<li><p><strong>memory_saving</strong> – If True, cached gradients will be cleared from memory
after computation to save space.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If no gradients are cached before computation,
    or if NaN values are detected during computation,
    or if external gradients are provided when using gradient factorization.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor.cache_gradients">
<span class="sig-name descname"><span class="pre">cache_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor.cache_gradients" title="Link to this definition">¶</a></dt>
<dd><p>Cache per-sample gradients for a specific epoch and training step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> – The current epoch number.</p></li>
<li><p><strong>batch_data</strong> – A tuple containing the batch of inputs and targets,
e.g., (inputs, labels).</p></li>
<li><p><strong>indices</strong> – A tensor containing the original indices for the samples
in batch_data.</p></li>
<li><p><strong>learning_rate</strong> – The learning rate for this step.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dattri.algorithm.dvemb.DVEmbAttributor.clear_cache">
<span class="sig-name descname"><span class="pre">clear_cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dattri.algorithm.dvemb.DVEmbAttributor.clear_cache" title="Link to this definition">¶</a></dt>
<dd><p>Clears cached gradients and factors to free memory.</p>
</dd></dl>

</dd></dl>

</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="hessian.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Hessian, HVP, and IHVP</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="task.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Tasks</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Dattri Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Attributors</a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorArnoldi.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorArnoldi.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorCG.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorCG.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorDataInf.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorDataInf.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorEKFAC.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorEKFAC.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorExplicit.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorExplicit.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.__init__"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.cache"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.generate_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.generate_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.generate_train_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.lissa_collate_fn"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.lissa_collate_fn()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.self_attribute"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.self_attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_test_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.transform_test_rep()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.influence_function.IFAttributorLiSSA.transform_train_rep"><code class="docutils literal notranslate"><span class="pre">IFAttributorLiSSA.transform_train_rep()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor"><code class="docutils literal notranslate"><span class="pre">TracInAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.cache"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.tracin.TracInAttributor.self_attribute"><code class="docutils literal notranslate"><span class="pre">TracInAttributor.self_attribute()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.cache"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.trak.TRAKAttributor.self_attribute"><code class="docutils literal notranslate"><span class="pre">TRAKAttributor.self_attribute()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor"><code class="docutils literal notranslate"><span class="pre">RPSAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.rps.RPSAttributor.cache"><code class="docutils literal notranslate"><span class="pre">RPSAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.data_shapley.KNNShapleyAttributor.cache"><code class="docutils literal notranslate"><span class="pre">KNNShapleyAttributor.cache()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.LoGraAttributor"><code class="docutils literal notranslate"><span class="pre">LoGraAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.LoGraAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">LoGraAttributor.__init__()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.cache"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_ifvp"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.compute_ifvp()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_preconditioners"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.compute_preconditioners()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.block_projected_if.BlockProjectedIFAttributor.compute_self_attribution"><code class="docutils literal notranslate"><span class="pre">BlockProjectedIFAttributor.compute_self_attribution()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.factgrass.FactGraSSAttributor"><code class="docutils literal notranslate"><span class="pre">FactGraSSAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.factgrass.FactGraSSAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">FactGraSSAttributor.__init__()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor</span></code></a><ul>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor.__init__"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor.__init__()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor.attribute"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor.attribute()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor.cache"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor.cache()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor.cache_gradients"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor.cache_gradients()</span></code></a></li>
<li><a class="reference internal" href="#dattri.algorithm.dvemb.DVEmbAttributor.clear_cache"><code class="docutils literal notranslate"><span class="pre">DVEmbAttributor.clear_cache()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>